"""
    Misc utils
"""
import os
from multiprocessing import Process
import torch as ch
import dill
import numpy as np
import torch as ch
from mib.models.utils import get_model


# Read environment variables
CACHE_PATH = os.environ.get("MIB_CACHE_SOURCE", None)
DATA_SOURCE = os.environ.get("MIB_DATA_SOURCE", None)


def get_models_path():
    """
    Get path to models.
    Returns:
        str: path to models
    """
    return os.path.join(get_cache_path(), "models")


def get_signals_path():
    """
    Get path to signals (generated by attacks).
    Returns:
        str: path to attack signals
    """
    return os.path.join(get_cache_path(), "signals")


def get_misc_path():
    """
    Get path to misc information (used/generated by attacks).
    Returns:
        str: path to misc information
    """
    return os.path.join(get_cache_path(), "misc")


def get_cache_path():
    """
    Get path to cache directory.
    Returns:
        str: path to cache directory
    """
    if CACHE_PATH is None:
        raise ValueError("MIB_CACHE_SOURCE= environment variable not set")
    return CACHE_PATH


def get_data_source():
    """
    Get path to data source directory.
    Returns:
        str: path to data source directory
    """
    if DATA_SOURCE is None:
        raise ValueError("MIB_DATA_SOURCE environment variable not set")
    return DATA_SOURCE


def meta_run_cache():
    """
        Cache for dumping run-wise processed features
        to speed up meta-classifier training.
        Returns:
            str: path to cache directory
    """
    if CACHE_PATH is None:
        raise ValueError("MIB_CACHE_SOURCE environment variable not set")
    return os.path.join(CACHE_PATH, "meta_run_cache")


class DillProcess(Process):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self._target = dill.dumps(
            self._target
        )  # Save the target function as bytes, using dill

    def run(self):
        if self._target:
            self._target = dill.loads(
                self._target
            )  # Unpickle the target function before executing
            self._target(*self._args, **self._kwargs)  # Execute the target function


def load_ref_models(model_dir, args, num_classes: int):
    if args.same_seed_ref:
        folder_to_look_in = os.path.join(
            model_dir, f"same_init/{args.target_model_index}"
        )
    else:
        folder_to_look_in = model_dir

    if args.specific_ref_folder is not None:
        folder_to_look_in = os.path.join(folder_to_look_in, args.specific_ref_folder)

    # Look specifically inside folder corresponding to this model's seed
    ref_models, ref_indices = [], []
    for m in os.listdir(folder_to_look_in):
        # Skip if directory
        if os.path.isdir(os.path.join(folder_to_look_in, m)):
            continue

        # Skip ref model if trained on exact same data split as target model
        # if m.split(".pt")[0].split("_")[0] == f"{args.target_model_index}":
        #    continue

        model, _, _ = get_model(args.model_arch, num_classes)
        state_dict = ch.load(os.path.join(folder_to_look_in, m))
        ref_indices.append(state_dict["train_index"])
        model.load_state_dict(state_dict["model"], strict=False)
        model.eval()
        ref_models.append(model)

    ref_indices = np.array(ref_indices, dtype=object)
    return ref_models, ref_indices
